{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee5b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pymongo\n",
    "import json\n",
    "import xmltodict\n",
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff2a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_clean_function(dict_to_clean):\n",
    "    \"\"\"\n",
    "    Function that deletes redundant words from the name of the fields of the dictionaries contained within the main one.\n",
    "    This recursive function will be used in order to modify each dictionary located below the current level.\n",
    "    This function does not return anything, since it modifies the original dictionary directly.\n",
    "    Args:\n",
    "        data_dict: information from a researcher stored in a python dictionary\n",
    "    \"\"\"\n",
    "    # Iterate through all keys of the current dictionary\n",
    "    for key_one in list(dict_to_clean):\n",
    "        key_one_clean = key_one\n",
    "        \n",
    "        # Same cleaning process as described in clean_dict_names function\n",
    "        if key_one_clean.count(':') == 1:\n",
    "            key_one_clean = key_one.split(':')[1]\n",
    "            dict_to_clean[key_one_clean] = dict_to_clean[key_one]\n",
    "            del dict_to_clean[key_one]\n",
    "        # If the current key starts with @ it is metadata that may not be relevant to query\n",
    "        # and may add noise to the json that will be added to the DB, so it is deleted\n",
    "        if key_one_clean[0]=='@':\n",
    "            del dict_to_clean[key_one_clean]\n",
    "            continue\n",
    "            \n",
    "        # If the fields (value associated with the current key key_one_clean) are stored in a dictionary\n",
    "        if isinstance(dict_to_clean[key_one_clean], dict):\n",
    "            # If the current field is a dictionary, and all the fields contained within start with \"@\" (metadata),\n",
    "            # it will be removed from the main dictionary in order to reduce noise\n",
    "            # If not, then the recursive function will be called again for the dictionary associated with key_one_clean\n",
    "            if all(dict_key.startswith('@') for dict_key in list(dict_to_clean[key_one_clean])):\n",
    "                del dict_to_clean[key_one_clean]\n",
    "                continue\n",
    "            else:\n",
    "                recursive_clean_function(dict_to_clean[key_one_clean])\n",
    "\n",
    "        # It may happen that the fields are stored in a list,\n",
    "        # therefore it is required to fetch the information contained within and create a new dictionary\n",
    "        # To do so, the keys will be the positions of the elements in the list\n",
    "        if isinstance(dict_to_clean[key_one_clean], list):\n",
    "            list_to_dict_data = {str(i):dict_to_clean[key_one_clean][i] \n",
    "                                 for i in range(len(dict_to_clean[key_one_clean]))}\n",
    "            dict_to_clean.update({key_one_clean:list_to_dict_data})\n",
    "            recursive_clean_function(dict_to_clean[key_one_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc634759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dict_names(data_dict):\n",
    "    \"\"\"\n",
    "    Function that deletes redundant words from the name of the fields in order to make the future queries easy to do.\n",
    "    If the input is a nested dictionary, then a recursive function will be used in order to modify each dictionary\n",
    "    located below the current level.\n",
    "    This function does not return anything, since it modifies the original dictionary directly.\n",
    "    Args:\n",
    "        data_dict: information from a researcher stored in a python dictionary\n",
    "    \"\"\"\n",
    "    for key_zero in list(data_dict):\n",
    "        # Knowing that the keys always can contain one colon, if there is one then it may follow\n",
    "        # the format 'person:person'. The first word is used by all the fields in the same level (excluding the ones\n",
    "        # starting with'@'),\n",
    "        # and the second one describes the field of interest. The last one should be maintained in order to find the fields\n",
    "        # by doing easier querys\n",
    "        key_zero_clean = key_zero\n",
    "        if key_zero_clean.count(':') == 1:\n",
    "            key_zero_clean = key_zero.split(':')[1]\n",
    "            data_dict[key_zero_clean] = data_dict[key_zero]\n",
    "            del data_dict[key_zero]\n",
    "        \n",
    "        # If data_dict is a nested dictionary, then recursion will be applied\n",
    "        if isinstance(data_dict[key_zero_clean], dict):\n",
    "            recursive_clean_function(data_dict[key_zero_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb61e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information_from_xml(xml_dict):\n",
    "    \"\"\"\n",
    "    Function that fetches the relevant information from the .xml file\n",
    "    and returns a dictionary ready to be uploaded to the database as a document.\n",
    "    If the xml file is not correct (i.e. wrong dictionary keys) an empty dictionary will be delivered.\n",
    "    Args:\n",
    "        xml_dict: information from a researcher stored in a dictionary\n",
    "    Returns:\n",
    "        researcher_data: dictionary that contains only the desired information \n",
    "        from the researcher if and only if the xml format is correct. If not, this dictionary will remain empty\n",
    "    \"\"\"\n",
    "    researcher_data = {}\n",
    "    # First ensure that the main key is 'record:record' in order to avoid reading wrong files\n",
    "    if 'record:record' in xml_dict:\n",
    "        # Now verify that the relevant keys are contained in the dictionary\n",
    "         if all(key in xml_dict['record:record'] for key in ('person:person', 'activities:activities-summary')):\n",
    "            # Extract the values for both keys and store it in a new dictionary that will contain\n",
    "            # only the relevant information, and therefore avoiding noise\n",
    "            researcher_data = {k: xml_dict['record:record'][k] for k in ('person:person', 'activities:activities-summary')}\n",
    "            \n",
    "            # In order to easily locate the document in the future (if the document needs to be updated or deleted for instance),\n",
    "            # a unique id will be defined. Knowing that each person has its unique id, it will be used as the document identification,\n",
    "            # since we want one document per person\n",
    "            researcher_data['_id']=researcher_data['person:person']['@path'].split('/')[1]\n",
    "            \n",
    "            # Before adding the dictionary to the database, a function will be applied\n",
    "            # in order to clean the names of the fields. This step will make the queries easier to write\n",
    "            clean_dict_names(researcher_data)\n",
    "                \n",
    "    return researcher_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49448371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data_folders(data_folder_path, mongodb_collection):\n",
    "    \"\"\"\n",
    "    Function that iterates over all the folders located in the given path and opens the .xml files within.\n",
    "    Args:\n",
    "        data_folder_path: folder that contains all the directories with the .xml\n",
    "        mongodb_collection: location within the database where the documents will be stored    \n",
    "    \"\"\"\n",
    "    # Iterate over each folder that contains .xml files\n",
    "    \n",
    "    task5 = []\n",
    "    for folder in os.listdir(data_folder_path):\n",
    "        print(folder)\n",
    "        # Iterate over each file and verify it has .xml format\n",
    "        for file in os.listdir(\"\".join([data_folder_path,\"/\",folder])):\n",
    "            if not file.endswith('.xml'): \n",
    "                continue\n",
    "            else:\n",
    "                file_path = Path(\"\".join([data_folder_path,\"/\",folder, \"/\", file]))\n",
    "                with open(file_path, encoding='utf8') as xml_file:\n",
    "                    # Transform the xml file to json, so the db input will be a dictionary\n",
    "                    data_dict = xmltodict.parse(xml_file.read())\n",
    "                    researcher_data = extract_information_from_xml(data_dict)\n",
    "                    # Verify that the dictionary is not empty\n",
    "                    if researcher_data:\n",
    "                        researcher_relevant_information = {}\n",
    "                        if 'name' in researcher_data['person']:\n",
    "\n",
    "                            if 'family-name' in researcher_data['person']['name']:\n",
    "                                researcher_relevant_information['family_name'] = researcher_data['person']['name']['family-name']\n",
    "                            if 'given-names' in researcher_data['person']['name']:\n",
    "                                researcher_relevant_information['given_names'] = researcher_data['person']['name']['given-names']\n",
    "                            if 'credit-name' in researcher_data['person']['name']:\n",
    "                                researcher_relevant_information['credit_name'] = researcher_data['person']['name']['credit-name']\n",
    "\n",
    "                        researcher_relevant_information['_id'] = researcher_data['_id']\n",
    "                        \n",
    "                        # Define a flag that will be added to the researcher file\n",
    "                        # If he has worked in Spain at least one time then this flag will be set as True\n",
    "                        has_studied_in_spain_flag = False\n",
    "                        \n",
    "                        if 'works' in researcher_data['activities-summary']:\n",
    "                            # Verify if there is only one organization or there are more than one\n",
    "                            # To do so, if there are many, then the main dictionary keys will be integers ('0', '1'...)\n",
    "                            # If not, then the key 'last-modified-date' will be there instead of the integers\n",
    "                            if 'last-modified-date' not in researcher_data['activities-summary']['works']['group']:\n",
    "                                for group in researcher_data['activities-summary']['works']['group']:\n",
    "                                    group_info = researcher_data['activities-summary']['works']['group'][str(group)]\n",
    "\n",
    "                                    researcher_position_data = {}\n",
    "                                    if 'title' in group_info['work-summary']:\n",
    "                                        researcher_position_data['title'] = group_info['work-summary']['title']['title']\n",
    "                                    if 'type' in group_info['work-summary']:\n",
    "                                        researcher_position_data['type'] = group_info['work-summary']['type']\n",
    "                                    if 'publication-date' in group_info['work-summary']:\n",
    "                                        if 'year' in group_info['work-summary']['publication-date']:\n",
    "                                            researcher_position_data['year'] = group_info['work-summary']['publication-date']['year']\n",
    "                                        if 'month' in group_info['work-summary']['publication-date']:\n",
    "                                            researcher_position_data['month'] = group_info['work-summary']['publication-date']['month']\n",
    "                                    if 'journal-title' in group_info['work-summary']:\n",
    "                                        researcher_position_data['journal_title'] = group_info['work-summary']['journal-title']\n",
    "                            else:\n",
    "                                group_info = researcher_data['activities-summary']['works']['group']\n",
    "                                researcher_position_data = {}\n",
    "                                if 'title' in group_info['work-summary']:\n",
    "                                    researcher_position_data['title'] = group_info['work-summary']['title']['title']\n",
    "                                if 'type' in group_info['work-summary']:\n",
    "                                    researcher_position_data['type'] = group_info['work-summary']['type']\n",
    "                                if 'publication-date' in group_info['work-summary']:\n",
    "                                    if 'year' in group_info['work-summary']['publication-date']:\n",
    "                                        researcher_position_data['year'] = group_info['work-summary']['publication-date']['year']\n",
    "                                    if 'month' in group_info['work-summary']['publication-date']:\n",
    "                                        researcher_position_data['month'] = group_info['work-summary']['publication-date']['month']\n",
    "                                if 'journal-title' in group_info['work-summary']:\n",
    "                                    researcher_position_data['journal_title'] = group_info['work-summary']['journal-title']\n",
    "\n",
    "                                # In order to follow the nomenclature when there are more than one position,\n",
    "                                # the unique position will be stored in a dictionary, using as key the number 0\n",
    "                                researcher_relevant_information['0'] = researcher_position_data\n",
    "                        # Assign the information to the researcher name\n",
    "                    if researcher_relevant_information:\n",
    "                        task5.append(researcher_relevant_information)\n",
    "                        # x = mongodb_collection.insert_one(researcher_relevant_information)\n",
    "                        researcher_relevant_information = {}\n",
    "    researcher_keys = []\n",
    "    for researcher_dict in task5:\n",
    "        researcher_keys.extend(list(researcher_dict))\n",
    "    researcher_keys = list(set(researcher_keys))\n",
    "    # Sort the list taking into account the integer keys, since we want the list\n",
    "    # to have first the id and the names instead of the int\n",
    "    #researcher_keys = sorted(researcher_keys, key=lambda x: (x.isdigit(), x))\n",
    "    \n",
    "    chars=[]\n",
    "    digits=[]\n",
    "    for value in researcher_keys:\n",
    "        if value.isdigit():\n",
    "            digits.append(int(value))\n",
    "        else:\n",
    "            chars.append(value)\n",
    "    chars.sort()\n",
    "    digits.sort()\n",
    "    # Sort the digits as integers and transform them again to str\n",
    "    digits=[str(elem) for elem in digits]\n",
    "    chars.extend(digits)\n",
    "    \n",
    "    researcher_keys = chars\n",
    "    '''with open('task5.csv', 'w', newline='', encoding='utf-8-sig') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, researcher_keys,  delimiter = \"/\")\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(task5)'''\n",
    "    df = pd.DataFrame(task5)\n",
    "    \n",
    "    df = df[chars]\n",
    "    df.to_csv('tarea5.csv',encoding='utf-8-sig', index=False, sep=\"/\", header = chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f3a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_researchers_list(mongodb_client, data_folder_path):\n",
    "    \"\"\"\n",
    "    Main function that aims to create a list with information from researchers stored in .xml files.\n",
    "    Args:\n",
    "        data_folder_path: folder that contains all the directories with the .xml\n",
    "    \"\"\"\n",
    "    researchers_client = pymongo.MongoClient(mongodb_client)\n",
    "    researchers_db = researchers_client[\"mydatabase\"]\n",
    "    researchers_col = researchers_db[\"researchers_work_data\"]\n",
    "    open_data_folders(data_folder_path, researchers_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d10ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=\"mongodb://localhost:27017/\"\n",
    "path=\"Directorios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4543f407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "001\n",
      "002\n",
      "00X\n",
      "01X\n",
      "02X\n"
     ]
    }
   ],
   "source": [
    "create_researchers_list(mongodb_client=client, data_folder_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab43041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f866719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
