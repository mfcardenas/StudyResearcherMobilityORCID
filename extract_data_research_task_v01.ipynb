{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee5b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pymongo\n",
    "import json\n",
    "import xmltodict\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff2a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_clean_function(dict_to_clean):\n",
    "    \"\"\"\n",
    "    Function that deletes redundant words from the name of the fields of the dictionaries contained within the main one.\n",
    "    This recursive function will be used in order to modify each dictionary located below the current level.\n",
    "    This function does not return anything, since it modifies the original dictionary directly.\n",
    "    Args:\n",
    "        data_dict: information from a researcher stored in a python dictionary\n",
    "    \"\"\"\n",
    "    # Iterate through all keys of the current dictionary\n",
    "    for key_one in list(dict_to_clean):\n",
    "        key_one_clean = key_one\n",
    "        \n",
    "        # Same cleaning process as described in clean_dict_names function\n",
    "        if key_one_clean.count(':') == 1:\n",
    "            key_one_clean = key_one.split(':')[1]\n",
    "            dict_to_clean[key_one_clean] = dict_to_clean[key_one]\n",
    "            del dict_to_clean[key_one]\n",
    "        # If the current key starts with @ it is metadata that may not be relevant to query\n",
    "        # and may add noise to the json that will be added to the DB, so it is deleted\n",
    "        if key_one_clean[0]=='@':\n",
    "            del dict_to_clean[key_one_clean]\n",
    "            continue\n",
    "            \n",
    "        # If the fields (value associated with the current key key_one_clean) are stored in a dictionary\n",
    "        if isinstance(dict_to_clean[key_one_clean], dict):\n",
    "            # If the current field is a dictionary, and all the fields contained within start with \"@\" (metadata),\n",
    "            # it will be removed from the main dictionary in order to reduce noise\n",
    "            # If not, then the recursive function will be called again for the dictionary associated with key_one_clean\n",
    "            if all(dict_key.startswith('@') for dict_key in list(dict_to_clean[key_one_clean])):\n",
    "                del dict_to_clean[key_one_clean]\n",
    "                continue\n",
    "            else:\n",
    "                recursive_clean_function(dict_to_clean[key_one_clean])\n",
    "\n",
    "        # It may happen that the fields are stored in a list,\n",
    "        # therefore it is required to fetch the information contained within and create a new dictionary\n",
    "        # To do so, the keys will be the positions of the elements in the list\n",
    "        if isinstance(dict_to_clean[key_one_clean], list):\n",
    "            list_to_dict_data = {str(i):dict_to_clean[key_one_clean][i] \n",
    "                                 for i in range(len(dict_to_clean[key_one_clean]))}\n",
    "            dict_to_clean.update({key_one_clean:list_to_dict_data})\n",
    "            recursive_clean_function(dict_to_clean[key_one_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc634759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dict_names(data_dict):\n",
    "    \"\"\"\n",
    "    Function that deletes redundant words from the name of the fields in order to make the future queries easy to do.\n",
    "    If the input is a nested dictionary, then a recursive function will be used in order to modify each dictionary\n",
    "    located below the current level.\n",
    "    This function does not return anything, since it modifies the original dictionary directly.\n",
    "    Args:\n",
    "        data_dict: information from a researcher stored in a python dictionary\n",
    "    \"\"\"\n",
    "    for key_zero in list(data_dict):\n",
    "        # Knowing that the keys always can contain one colon, if there is one then it may follow\n",
    "        # the format 'person:person'. The first word is used by all the fields in the same level (excluding the ones\n",
    "        # starting with'@'),\n",
    "        # and the second one describes the field of interest. The last one should be maintained in order to find the fields\n",
    "        # by doing easier querys\n",
    "        key_zero_clean = key_zero\n",
    "        if key_zero_clean.count(':') == 1:\n",
    "            key_zero_clean = key_zero.split(':')[1]\n",
    "            data_dict[key_zero_clean] = data_dict[key_zero]\n",
    "            del data_dict[key_zero]\n",
    "        \n",
    "        # If data_dict is a nested dictionary, then recursion will be applied\n",
    "        if isinstance(data_dict[key_zero_clean], dict):\n",
    "            recursive_clean_function(data_dict[key_zero_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb61e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information_from_xml(xml_dict):\n",
    "    \"\"\"\n",
    "    Function that fetches the relevant information from the .xml file\n",
    "    and returns a dictionary ready to be uploaded to the database as a document.\n",
    "    If the xml file is not correct (i.e. wrong dictionary keys) an empty dictionary will be delivered.\n",
    "    Args:\n",
    "        xml_dict: information from a researcher stored in a dictionary\n",
    "    Returns:\n",
    "        researcher_data: dictionary that contains only the desired information \n",
    "        from the researcher if and only if the xml format is correct. If not, this dictionary will remain empty\n",
    "    \"\"\"\n",
    "    researcher_data = {}\n",
    "    # First ensure that the main key is 'record:record' in order to avoid reading wrong files\n",
    "    if 'record:record' in xml_dict:\n",
    "        # Now verify that the relevant keys are contained in the dictionary\n",
    "         if all(key in xml_dict['record:record'] for key in ('person:person', 'activities:activities-summary')):\n",
    "            # Extract the values for both keys and store it in a new dictionary that will contain\n",
    "            # only the relevant information, and therefore avoiding noise\n",
    "            researcher_data = {k: xml_dict['record:record'][k] for k in ('person:person', 'activities:activities-summary')}\n",
    "            \n",
    "            # In order to easily locate the document in the future (if the document needs to be updated or deleted for instance),\n",
    "            # a unique id will be defined. Knowing that each person has its unique id, it will be used as the document identification,\n",
    "            # since we want one document per person\n",
    "            researcher_data['_id']=researcher_data['person:person']['@path'].split('/')[1]\n",
    "            \n",
    "            # Before adding the dictionary to the database, a function will be applied\n",
    "            # in order to clean the names of the fields. This step will make the queries easier to write\n",
    "            clean_dict_names(researcher_data)\n",
    "                \n",
    "    return researcher_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49448371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data_folders(data_folder_path, mongodb_collection):\n",
    "    \"\"\"\n",
    "    Function that iterates over all the folders located in the given path and opens the .xml files within.\n",
    "    Args:\n",
    "        data_folder_path: folder that contains all the directories with the .xml\n",
    "        mongodb_collection: location within the database where the documents will be stored    \n",
    "    \"\"\"\n",
    "    # Iterate over each folder that contains .xml files\n",
    "    task1 = {}\n",
    "    for folder in os.listdir(data_folder_path):\n",
    "        print(folder)\n",
    "        # Iterate over each file and verify it has .xml format\n",
    "        for file in os.listdir(\"\".join([data_folder_path,\"/\",folder])):\n",
    "            if not file.endswith('.xml'): \n",
    "                continue\n",
    "            else:\n",
    "                file_path = Path(\"\".join([data_folder_path,\"/\",folder, \"/\", file]))\n",
    "                with open(file_path, encoding='utf8') as xml_file:\n",
    "                    # Transform the xml file to json, so the db input will be a dictionary\n",
    "                    data_dict = xmltodict.parse(xml_file.read())\n",
    "                    researcher_data = extract_information_from_xml(data_dict)\n",
    "                    # Verify that the dictionary is not empty\n",
    "                    if researcher_data:\n",
    "                        if 'educations' in researcher_data['activities-summary']:\n",
    "                            if 'affiliation-group' in researcher_data['activities-summary']['educations']:\n",
    "                                # Verify if there is only one organization or there are more than one\n",
    "                                # To do so, if there are many, then the main dictionary keys will be integers ('0', '1'...)\n",
    "                                # If not, then the key 'last-modified-date' will be there instead of the integers\n",
    "                                if 'last-modified-date' not in researcher_data['activities-summary']['educations']['affiliation-group']:\n",
    "                                    for group in researcher_data['activities-summary']['educations']['affiliation-group']:\n",
    "                                        group_info = researcher_data['activities-summary']['educations']['affiliation-group'][str(group)]\n",
    "                                        organization = group_info['education-summary']['organization']\n",
    "                                        country = organization['address']['country']\n",
    "                                        if country not in task1:\n",
    "                                            task1[country] = []\n",
    "                                            task1[country].append(organization['name'])\n",
    "                                        else:\n",
    "                                            if organization['name'] not in task1[country]:\n",
    "                                                task1[country].append(organization['name'])\n",
    "                                else:\n",
    "                                    group_info = researcher_data['activities-summary']['educations']['affiliation-group']\n",
    "                                    organization = group_info['education-summary']['organization']\n",
    "                                    country = organization['address']['country']\n",
    "                                    if country not in task1:\n",
    "                                        task1[country] = []\n",
    "                                        task1[country].append(organization['name'])\n",
    "                                    else:\n",
    "                                        if organization['name'] not in task1[country]:\n",
    "                                            task1[country].append(organization['name'])\n",
    "                            \n",
    "                            \n",
    "                        # It may happen that the researcher has 'employments' field\n",
    "                        if 'employments' in researcher_data['activities-summary']:\n",
    "                            if 'affiliation-group' in researcher_data['activities-summary']['employments']:\n",
    "                                # Verify if there is only one organization or there are more than one\n",
    "                                # To do so, if there are many, then the main dictionary keys will be integers ('0', '1'...)\n",
    "                                # If not, then the key 'last-modified-date' will be there instead of the integers\n",
    "                                if 'last-modified-date' not in researcher_data['activities-summary']['employments']['affiliation-group']:\n",
    "                                    for group in researcher_data['activities-summary']['employments']['affiliation-group']:\n",
    "                                        group_info = researcher_data['activities-summary']['employments']['affiliation-group'][str(group)]\n",
    "                                        organization = group_info['employment-summary']['organization']\n",
    "                                        country = organization['address']['country']\n",
    "                                        if country not in task1:\n",
    "                                            task1[country] = []\n",
    "                                            task1[country].append(organization['name'])\n",
    "                                        else:\n",
    "                                            if organization['name'] not in task1[country]:\n",
    "                                                task1[country].append(organization['name'])\n",
    "                                else:\n",
    "                                    group_info = researcher_data['activities-summary']['employments']['affiliation-group']\n",
    "                                    organization = group_info['employment-summary']['organization']\n",
    "                                    country = organization['address']['country']\n",
    "                                    if country not in task1:\n",
    "                                        task1[country] = []\n",
    "                                        task1[country].append(organization['name'])\n",
    "                                    else:\n",
    "                                        if organization['name'] not in task1[country]:\n",
    "                                            task1[country].append(organization['name'])\n",
    "    if task1:\n",
    "        cols = ['Country', 'Institutions']\n",
    "        rows = []\n",
    "        for key, value in task1.items():\n",
    "            rows.append([key, \", \".join(value).replace('\"', '')])\n",
    "        df = pd.DataFrame(rows, columns=cols)\n",
    "        df.to_csv('tarea1.csv',encoding='utf-8-sig', index=False, sep=\"/\")\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_researchers_list(mongodb_client, data_folder_path):\n",
    "    \"\"\"\n",
    "    Main function that aims to create a list with information from researchers stored in .xml files.\n",
    "    Args:\n",
    "        data_folder_path: folder that contains all the directories with the .xml\n",
    "    \"\"\"\n",
    "    researchers_client = pymongo.MongoClient(mongodb_client)\n",
    "    researchers_db = researchers_client[\"mydatabase\"]\n",
    "    researchers_col = researchers_db[\"universities_per_country\"]\n",
    "    open_data_folders(data_folder_path, researchers_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d10ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=\"mongodb://localhost:27017/\"\n",
    "path=\"\\BD ORCID\\ORCID_2021\\ORCID_2021_10_summaries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_researchers_list(mongodb_client=client, data_folder_path=path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
